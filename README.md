Data Acquisition:
Definition: Data acquisition is the process of collecting raw data from various sources such as databases, APIs, files, sensors, or manual entry.
Methods:
Web Scraping: Extracting data from websites using tools like BeautifulSoup or Scrapy.
APIs: Accessing data from application programming interfaces (APIs) provided by platforms like Twitter, Google, or financial data providers.
Databases: Retrieving data from relational databases (SQL) or NoSQL databases.
Files: Reading data from CSV, JSON, Excel, or other file formats.
Data Wrangling:
Definition: Data wrangling, also known as data munging, is the process of cleaning, transforming, and organizing raw data into a suitable format for analysis.
Steps:
Data Cleaning: Handling missing values, correcting data types, removing duplicates, and dealing with outliers.
Data Transformation: Converting data into a consistent format, scaling features, encoding categorical variables, and creating new features.
Data Integration: Combining multiple data sources or tables into a unified dataset.
Data Reduction: Aggregating or summarizing data to reduce its size while preserving relevant information.
Data acquisition lays the foundation by bringing in data, while data wrangling prepares the data for analysis by ensuring its quality, consistency, and usability. These processes are crucial in the data science pipeline for extracting meaningful insights and building reliable models.
            
